{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879a2a4e-456c-4894-8f91-5afad4e96892",
   "metadata": {},
   "source": [
    "## A simple ML pipeline demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4779b8e1-3c8d-48bb-8adb-485128e9e441",
   "metadata": {},
   "source": [
    "### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03890e-9dd7-4c2f-99f2-c608dfbb06f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import NamedTuple\n",
    "from datetime import datetime\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "from kfp.v2.dsl import pipeline\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.dsl import OutputPath\n",
    "from kfp.v2.dsl import InputPath\n",
    "from kfp.v2.dsl import Model\n",
    "from kfp.v2.dsl import Input\n",
    "from kfp.v2.dsl import Artifact\n",
    "from kfp.v2.dsl import Output\n",
    "from kfp.v2.dsl import Metrics\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1edb5a-373d-4c65-9137-e6c817942d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters for GCP and kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad2d39-e19a-417d-973a-cabb3e8a723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: it's not the best practice\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"  # Your service credentials (assume json)\n",
    "PROJECT_ID = \"\"  # Your project id\n",
    "SERVICE_ACCOUNT = \"\"  # assume XXXX@YYYYY.iam.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6373ea-67a4-4d32-ae9e-04b5d3dd7562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fb8db-ebf1-4c67-90f4-81395ae68aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENABLE_CACHING = False\n",
    "\n",
    "PIPELINE_NAME = \"my-kfp-on-gcp-demo\"\n",
    "# Your Kubeflow's detail\n",
    "TEMPLATE_PATH = \"ml_pipeline_w_mlf_demo.json\"\n",
    "# GCS Bucket to store artefacts\n",
    "PIPELINE_ROOT = f\"gs://kfp-demo-bucket-{PROJECT_ID}\"\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
    "\n",
    "# Parameters for ML\n",
    "DATASET_ID = \"sklearn_default_housing\"\n",
    "TABLE_ID = \"NA\"\n",
    "COL_LABEL = \"MedHouseVal\"\n",
    "COL_TRAINING = [\"some_list\"]\n",
    "\n",
    "# NB: these parameters must be added for your pipeline's args\n",
    "PIPELINE_PARAMS = {\n",
    "    \"project_id\": PROJECT_ID,\n",
    "    \"table_id\": TABLE_ID,\n",
    "    \"dataset_id\": DATASET_ID,\n",
    "    \"col_label\": COL_LABEL,\n",
    "    \"col_training\": COL_TRAINING,\n",
    "    \"datasplit_seed\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7839a00-3694-4023-8ca2-3aadec4d80ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1657fbc-1b98-492b-9bee-1edf4bf3f1fd",
   "metadata": {},
   "source": [
    "#### 1.a: Traditional way to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1e467-d36a-483f-951d-ef6b0e85fd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Function to return the orignal data\n",
    "def load_my_data_local():\n",
    "    '''\n",
    "    Load data\n",
    "    '''\n",
    "    # Load data\n",
    "    cal_data = fetch_california_housing(as_frame=True)\n",
    "    df = cal_data.frame\n",
    "\n",
    "    # In reality, the data load process would be\n",
    "    # requests, or pulling data from data warehouse\n",
    "    # df = pd.read_csv(f\"{loc}/{tablename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_my_data_local()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8f085-b2a8-4cd8-a7f9-ecc83a1ae504",
   "metadata": {},
   "source": [
    "#### 1.b: Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04fd45-7de6-43be-8806-26dd8376afab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to return the orignal data\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"pandas==1.5.3\", \"scikit-learn==1.2.2\"],\n",
    ")\n",
    "def load_my_data(output_csv: OutputPath(\"CSV\")) -> None:\n",
    "    \"\"\"\n",
    "    Load data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "    # Load data\n",
    "    cal_data = fetch_california_housing(as_frame=True)\n",
    "    df = cal_data.frame\n",
    "\n",
    "    # In reality, the data load process would be\n",
    "    # requests, or pulling data from data warehouse\n",
    "    # df = pd.read_csv(f\"{loc}/{tablename}\")\n",
    "\n",
    "    # Create an output\n",
    "    df.to_csv(output_csv, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4357bc-c154-4c03-837e-88b94a441492",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635908a7-4a6d-46b5-b601-68e0c24f840f",
   "metadata": {},
   "source": [
    "#### 2.a: Tradtional way to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461139b-b5b8-4ab4-9ded-7b5f64ec43f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess data for ml model\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_my_data_local(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Some preprocessing\n",
    "    \"\"\"\n",
    "    # Create a new feature\n",
    "    df['AveRooms_bin'] = pd.to_numeric(pd.cut(x = df['AveRooms'], \n",
    "                            bins = [0, 3, 5, 7, 10, 300], \n",
    "                            labels = [1, 2, 3, 4, 5]\n",
    "                            ))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_processed = preprocess_my_data_local(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1146f4f-67ec-4258-8e92-c52019ab0cec",
   "metadata": {},
   "source": [
    "#### 2.b: Kubeflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6bbb4-83d0-4b78-9b6b-e94ba773bba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.10\", packages_to_install=[\"pandas==1.5.3\"])\n",
    "def preprocess_my_data(input_csv: InputPath(\"CSV\"), output_csv: OutputPath(\"CSV\")):\n",
    "    \"\"\"\n",
    "    Some preprocessing\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    # Create a new feature\n",
    "    df[\"AveRooms_bin\"] = pd.to_numeric(\n",
    "        pd.cut(x=df[\"AveRooms\"], bins=[0, 3, 5, 7, 10, 300], labels=[1, 2, 3, 4, 5])\n",
    "    )\n",
    "\n",
    "    # Create an output\n",
    "    df.to_csv(output_csv, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7197ce5-276a-40dd-8335-48a982d12492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8544d5-91dc-4671-a84f-5196326590b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a876b1-054e-4ee7-82a5-f130f5762c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\n",
    "        \"pandas==1.5.3\",\n",
    "        \"scikit-learn==1.2.2\",\n",
    "        \"numpy==1.23.5\",\n",
    "        \"mlflow==2.2.2\",\n",
    "    ],\n",
    ")\n",
    "def train_ml_model_with_mlflow(\n",
    "    input_csv: InputPath(\"CSV\"), datasplit_seed: int\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\", [(\"val_mse\", float), (\"val_mae\", float), (\"model_location\", str)]\n",
    "):\n",
    "    \"\"\"\n",
    "    Some training\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    import pandas as pd\n",
    "    import mlflow\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Split Features and Labels\n",
    "    X = df.drop([\"AveRooms\", \"MedHouseVal\"], axis=1)\n",
    "    y = df[\"MedHouseVal\"]\n",
    "\n",
    "    # Split the data for train (80%) and validation (20%)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=datasplit_seed\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(run_name=\"my_kfp_house_reg\"):\n",
    "        elastic_net_reg = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\n",
    "        elastic_net_reg.fit(X_train, y_train)\n",
    "        result = mlflow.sklearn.log_model(elastic_net_reg, \"model\")\n",
    "\n",
    "    y_val_pred = elastic_net_reg.predict(X_val)\n",
    "\n",
    "    val_mse = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_mae = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    return (val_mse, val_mae, f\"{mlflow.get_artifact_uri()}/{result.artifact_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabb01e-8166-4ce4-b3be-45c607355b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ae69e6-6b28-47ce-b331-35b37a73df5c",
   "metadata": {},
   "source": [
    "### 4. Pipeline (concat multiple components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bf2e1-81f5-4a93-963c-f00aeda26972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a pipeline and create a task from a component:\n",
    "@pipeline(name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT)\n",
    "def my_ml_pipeline_with_kfp(\n",
    "    project_id: str,\n",
    "    table_id: str,\n",
    "    dataset_id: str,\n",
    "    col_label: str,\n",
    "    col_training: list,\n",
    "    datasplit_seed: int,\n",
    "):\n",
    "    load_task = load_my_data()\n",
    "    preprocess_task = preprocess_my_data(input_csv=load_task.outputs[\"output_csv\"])\n",
    "    train_task = train_ml_model_with_mlflow(\n",
    "        input_csv=preprocess_task.outputs[\"output_csv\"], datasplit_seed=datasplit_seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe76cd-c2ba-4366-97b5-5508aa611bf6",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622acd3-ed42-4eba-9ee4-0a07d7449efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=my_ml_pipeline_with_kfp, package_path=TEMPLATE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2414ad-4f55-49a1-bbf8-f7115bd2daa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf7161c-7626-490b-b77a-5a8da4a4cace",
   "metadata": {},
   "source": [
    "### 5. Deploy on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fe141-4ff6-4e30-98e5-65a0c81522cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=PIPELINE_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde3db5-e5d3-4d45-a5ef-99fa69beb94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
    "    enable_caching=ENABLE_CACHING,\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=TEMPLATE_PATH,\n",
    "    job_id=JOBID,\n",
    "    parameter_values=PIPELINE_PARAMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18679c-f2ac-4b33-bb62-37b6375840ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_.submit(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f6781-f4ca-4242-8cb8-63d605afd92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818acc4a-438c-4d8e-84e5-065c47b66fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
