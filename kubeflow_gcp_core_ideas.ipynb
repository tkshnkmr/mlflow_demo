{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45bca5d-6c68-43d4-8a4c-fd513838c347",
   "metadata": {},
   "source": [
    "## Vertex AI Pipelines with Kubeflow Pipelines (Basic components)\n",
    "- Written by Takashi Nakamura\n",
    "- Vertex AI documentation: https://cloud.google.com/vertex-ai/docs\n",
    "- Kubeflow documentation: https://www.kubeflow.org/docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eba851-79be-4b08-88b6-e9b87a71a7d8",
   "metadata": {},
   "source": [
    "### Import relevant package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2597fc-d2c7-475b-a102-3482adbdd2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import kfp\n",
    "\n",
    "from kfp.v2.dsl import pipeline\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09ff98-8eaf-4b9b-9601-c4ffacc9ebba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### -1. Pre-requisite\n",
    "- Create a GCP account\n",
    "- Enable relevant APIs, services (e.g., Kubernetes, vertex AI, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9e3b6-c8ac-41d8-b3dc-c3f274274f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2bf1bed-030c-40f6-83d2-6b6a86802712",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0. Parameters for GCP and kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23762b03-5721-49d6-9e70-abe6a87a135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: it's not the best practice\n",
    "PROJECT_ID = \"\"  # Your project id\n",
    "SERVICE_ACCOUNT = \"\"  # assume XXXX@YYYYY.iam.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd40a3-4b0d-4705-a0f4-8ea9da62d873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea31139-58fe-4ae5-b3d0-0aed087f699b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate aiplatform (Vertex AI)\n",
    "aiplatform.init(project=PROJECT_ID, staging_bucket=PIPELINE_ROOT)\n",
    "\n",
    "PIPELINE_NAME = \"vertex-ai-kfp-gcp-demo-notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d605bb-d1ef-45ba-8eb8-08e80615fee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base image\n",
    "PYTHON_BASE = \"python:3.10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5d919-8775-4de2-a1c6-a5d78c78dd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Basic: simple example\n",
    "- Change the component name\n",
    "- Provide machine spec to run on Vertex AI\n",
    "- Create the order of the components\n",
    "- Python version is 3.7 (by default?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad5c2a-8932-4cc2-88cb-7ee83e5529b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component()\n",
    "def produce_msg_op(my_name: str) -> str:\n",
    "    return f\"Hello, {my_name}!\"\n",
    "\n",
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def print_msg_op(my_msg: str):\n",
    "    print(my_msg)\n",
    "    \n",
    "@kfp.v2.dsl.component()\n",
    "def check_nvidia_smi_op():\n",
    "    import subprocess\n",
    "    subprocess.run(\"nvidia-smi\", shell=True)\n",
    "\n",
    "@kfp.v2.dsl.pipeline(name=\"pipeline1\")\n",
    "def my_pipeline_1():\n",
    "    \"\"\"\n",
    "    Pipeline code\n",
    "    \"\"\"\n",
    "    # 1st component\n",
    "    msg_task_0 = produce_msg_op(\"GCP Vertex AI Learning Team\").set_display_name(\"component0\")\n",
    "    # 2nd component\n",
    "    print_msg_task_0 = print_msg_op(msg_task_0.output).set_display_name(\"component1\").set_cpu_limit(\"5\")\n",
    "    # 3rd component\n",
    "    print_msg_op(\"This is component2!\").after(print_msg_task_0).set_display_name(\"component2\").set_memory_limit(\"10\")\n",
    "    \n",
    "    # Different way to create the pipeline relationship\n",
    "    msg_task_1 = produce_msg_op(\"GCP Vertex AI Learning Team\").set_display_name(\"component3\")\n",
    "    print_msg_task_1 = produce_msg_op(msg_task_1.output).set_display_name(\"component4\")\n",
    "    print_msg_task_2 = produce_msg_op(\"This is component5!\").set_display_name(\"component5\")\n",
    "    # Explicitly mention the relationshop\n",
    "    print_msg_task_1.after(msg_task_1)\n",
    "    print_msg_task_2.after(print_msg_task_1)\n",
    "    \n",
    "    # check_nvidia_smi_op().set_display_name(\"component3\").add_node_selector_constraint(\"cloud.google.com/gke-accelerator\", \"NVIDIA_TESLA_T4\").set_gpu_limit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6104106-7565-45e3-ab6d-5e8662e4cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "pipeline_detail_json = \"pipeline_1.json\"\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline_1, package_path=pipeline_detail_json)\n",
    "\n",
    "# Check the current time\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
    "\n",
    "# Pipeline job\n",
    "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
    "    enable_caching=False,\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=pipeline_detail_json,\n",
    "    job_id=JOBID,\n",
    "    parameter_values={},\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "pipeline_.submit(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbae389-62d5-41dc-89a6-16bf7b072e21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Run the component after the completion\n",
    "- ```kfp.v2.dsl.ExitHandler``` supports to check the completion\n",
    "- ```kfp.v2.dsl.PipelineTaskFinalStatus``` can configure to run certain tasks if the previous task failed \n",
    "    - NB: But currently has some bugs?\n",
    "    - https://github.com/kubeflow/pipelines/issues/8649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe716b-95fa-40de-93aa-35a8b05d5f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import PipelineTaskFinalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89005b7e-df07-475a-b3aa-c828ba10636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def exit_func(my_msg: str, my_status: PipelineTaskFinalStatus):\n",
    "    print(my_msg)\n",
    "    print(\"my_status.state\", my_status.state)\n",
    "    print(\"my_status.error_code\", my_status.error_code)\n",
    "    print(\"my_status.error_message\", my_status.error_message)\n",
    "\n",
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def raise_value_error():\n",
    "    raise ValueError(\"Raised ValueError\")\n",
    "\n",
    "@kfp.v2.dsl.pipeline(name=\"pipeline2\")\n",
    "def my_pipeline_2():\n",
    "    exit_task_0 = exit_func(\"Run exit_op for Value Error\")\n",
    "    \n",
    "    # Value error\n",
    "    with kfp.v2.dsl.ExitHandler(exit_op=exit_task_0):\n",
    "        previous_task_0 = raise_value_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9648b8b-6205-471a-b5fa-72c33ca2345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "pipeline_detail_json = \"pipeline_2.json\"\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline_2, package_path=pipeline_detail_json)\n",
    "\n",
    "# Check the current time\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
    "\n",
    "# Pipeline job\n",
    "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
    "    enable_caching=False,\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=pipeline_detail_json,\n",
    "    job_id=JOBID,\n",
    "    parameter_values={},\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "pipeline_.submit(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c94c9d-a157-4940-a3ce-0617e599e1c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Condition\n",
    "- If-Not confition for components using ```kfp.v2.dsl.Condition```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3fe52-7eda-4a74-87a8-9f5871fcca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def produce_random_num_func() -> float:\n",
    "    import random\n",
    "    return random.random()\n",
    "\n",
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def print_val_op(val: float):\n",
    "    print(val)\n",
    "\n",
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def raise_value_error(val: float):\n",
    "    raise ValueError(f\"The provided value, {val}, must be greater than 0.5\")\n",
    "\n",
    "@kfp.v2.dsl.pipeline(name=\"pipeline3\")\n",
    "def my_pipeline_3():\n",
    "    produce_task_0 = produce_random_num_func()\n",
    "    # Condition 1\n",
    "    with kfp.v2.dsl.Condition(produce_task_0.output>0.5, name=\"Provided value greater than\"):\n",
    "        print_val_op(produce_task_0.output)\n",
    "    # Condition 2\n",
    "    with kfp.v2.dsl.Condition(produce_task_0.output<=0.5, name=\"Provided value smaller than\"):\n",
    "        raise_value_error(produce_task_0.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307f840-1210-4202-b688-b76b8d8dc76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "pipeline_detail_json = \"pipeline_3.json\"\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline_3, package_path=pipeline_detail_json)\n",
    "\n",
    "# Check the current time\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
    "\n",
    "# Pipeline job\n",
    "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
    "    enable_caching=False,\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=pipeline_detail_json,\n",
    "    job_id=JOBID,\n",
    "    parameter_values={},\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "pipeline_.submit(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e3a49-396d-4900-8950-8cc14c0301cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Run jobs parallelly\n",
    "- a) ```kfp.v2.dsl.ParallelFor```\n",
    "- b) A normal python ```for``` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5848b-2045-45b7-9add-b6c396ecce6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(base_image=PYTHON_BASE)\n",
    "def produce_num_func(val: int) -> float:\n",
    "    import random\n",
    "    return val * random.random()\n",
    "\n",
    "@kfp.v2.dsl.pipeline(name=\"pipeline4\")\n",
    "def my_pipeline_4():\n",
    "    num_ls = [i for i in range(5)]\n",
    "    \n",
    "    # Parallel     \n",
    "    with kfp.v2.dsl.ParallelFor(num_ls) as v:\n",
    "        produce_num_func(v).set_display_name(f\"Produce number\")\n",
    "        \n",
    "    # NB: We are able to use a normal for loop\n",
    "    for v in num_ls:\n",
    "        produce_num_func(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5becaadd-fd05-4287-bc44-3a99398d8cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "pipeline_detail_json = \"pipeline_4.json\"\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline_4, package_path=pipeline_detail_json)\n",
    "\n",
    "# Check the current time\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "JOBID = f\"training-pipeline-{TIMESTAMP}\"\n",
    "\n",
    "# Pipeline job\n",
    "pipeline_ = aiplatform.pipeline_jobs.PipelineJob(\n",
    "    enable_caching=False,\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=pipeline_detail_json,\n",
    "    job_id=JOBID,\n",
    "    parameter_values={},\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "pipeline_.submit(service_account=SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcd940-823b-45de-a23b-93a55d8cee59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
